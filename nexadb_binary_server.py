#!/usr/bin/env python3
"""
NexaDB Binary Protocol Server
==============================

High-performance binary protocol server for NexaDB with:
- Custom binary protocol (3-10x faster than HTTP/JSON)
- MessagePack encoding (2-10x faster than JSON)
- Persistent TCP connections
- Connection pooling (1000+ concurrent connections)
- Streaming results for large queries

Protocol Specification:
----------------------
Message Format:
  Header (12 bytes):
    - Magic (4 bytes): 0x4E455841 ("NEXA")
    - Version (1 byte): 0x01
    - Message Type (1 byte): 0x01-0xFF
    - Flags (2 bytes): Reserved for future use
    - Payload Length (4 bytes): uint32

  Payload (variable):
    - MessagePack encoded data

Message Types:
  Client ‚Üí Server:
    0x01 = CONNECT       - Handshake + authentication
    0x02 = CREATE        - Insert document
    0x03 = READ          - Get document by key
    0x04 = UPDATE        - Update document
    0x05 = DELETE        - Delete document
    0x06 = QUERY         - Query with filters
    0x07 = VECTOR_SEARCH - Vector similarity search
    0x08 = BATCH_WRITE   - Bulk insert
    0x09 = PING          - Keep-alive

  Server ‚Üí Client:
    0x81 = SUCCESS       - Operation succeeded
    0x82 = ERROR         - Operation failed
    0x83 = NOT_FOUND     - Key doesn't exist
    0x84 = DUPLICATE     - Key already exists
    0x85 = STREAM_START  - Beginning of result stream
    0x86 = STREAM_CHUNK  - Partial results
    0x87 = STREAM_END    - End of results
    0x88 = PONG          - Keep-alive response

Usage:
------
    python3 nexadb_binary_server.py --host 0.0.0.0 --port 6970
"""

import socket
import struct
import threading
import time
import sys
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Any, Optional

# MessagePack for binary serialization
try:
    import msgpack
except ImportError:
    print("[ERROR] msgpack not installed. Installing...")
    import subprocess
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'msgpack'])
    import msgpack

import hashlib
import json
import os

# Import NexaDB core
sys.path.append('.')
from veloxdb_core import VeloxDB
from toon_format import json_to_toon, toon_to_json
from unified_auth import UnifiedAuthManager


class NexaDBBinaryProtocol:
    """Binary protocol constants and utilities"""

    # Protocol magic and version
    MAGIC = 0x4E455841  # "NEXA" in hex
    VERSION = 0x01

    # Client ‚Üí Server message types
    MSG_CONNECT = 0x01
    MSG_CREATE = 0x02
    MSG_READ = 0x03
    MSG_UPDATE = 0x04
    MSG_DELETE = 0x05
    MSG_QUERY = 0x06
    MSG_VECTOR_SEARCH = 0x07
    MSG_BATCH_WRITE = 0x08
    MSG_PING = 0x09
    MSG_DISCONNECT = 0x0A
    MSG_QUERY_TOON = 0x0B  # Query with TOON format response
    MSG_EXPORT_TOON = 0x0C  # Export collection to TOON format
    MSG_IMPORT_TOON = 0x0D  # Import TOON data into collection
    MSG_CREATE_USER = 0x0E  # Create new user (admin only)
    MSG_DELETE_USER = 0x0F  # Delete user (admin only)
    MSG_LIST_USERS = 0x10  # List all users (admin only)
    MSG_CHANGE_PASSWORD = 0x11  # Change user password
    MSG_LIST_COLLECTIONS = 0x20  # List all collections
    MSG_DROP_COLLECTION = 0x21  # Drop a collection
    MSG_GET_VECTORS = 0x23  # Get vector statistics
    MSG_SUBSCRIBE_CHANGES = 0x30  # Subscribe to change stream
    MSG_UNSUBSCRIBE_CHANGES = 0x31  # Unsubscribe from change stream

    # NEW v3.0.0: Database operations
    MSG_LIST_DATABASES = 0x40  # List all databases
    MSG_DROP_DATABASE = 0x42  # Drop a database
    MSG_BUILD_HNSW_INDEX = 0x45  # Build HNSW index for vector collection

    # NEW v3.0.0: MongoDB import
    MSG_IMPORT_MONGODB_DB = 0x50  # Import entire MongoDB database
    MSG_IMPORT_MONGODB_COLLECTION = 0x51  # Import single MongoDB collection

    # Server ‚Üí Client response types
    MSG_SUCCESS = 0x81
    MSG_ERROR = 0x82
    MSG_NOT_FOUND = 0x83
    MSG_DUPLICATE = 0x84
    MSG_STREAM_START = 0x85
    MSG_STREAM_CHUNK = 0x86
    MSG_STREAM_END = 0x87
    MSG_PONG = 0x88
    MSG_CHANGE_EVENT = 0x90  # Server pushes change events

    @staticmethod
    def pack_message(msg_type: int, data: Any) -> bytes:
        """
        Pack message into binary protocol format.

        Args:
            msg_type: Message type code
            data: Data to encode (will be MessagePack encoded)

        Returns:
            Binary message (header + payload)
        """
        # Encode payload with MessagePack
        payload = msgpack.packb(data, use_bin_type=True)

        # Build header (12 bytes)
        header = struct.pack(
            '>IBBHI',
            NexaDBBinaryProtocol.MAGIC,    # Magic (4 bytes)
            NexaDBBinaryProtocol.VERSION,  # Version (1 byte)
            msg_type,                       # Message type (1 byte)
            0,                              # Flags (2 bytes)
            len(payload)                    # Payload length (4 bytes)
        )

        return header + payload

    @staticmethod
    def unpack_header(header_bytes: bytes) -> tuple:
        """
        Unpack message header.

        Args:
            header_bytes: 12 bytes of header

        Returns:
            (magic, version, msg_type, flags, payload_len)
        """
        return struct.unpack('>IBBHI', header_bytes)


class NexaDBBinaryServer:
    """
    Binary protocol server for NexaDB.

    Features:
    - Persistent TCP connections
    - Connection pooling (1000+ concurrent)
    - Binary protocol (3-10x faster than HTTP)
    - Streaming results for large queries
    - Automatic reconnection handling
    """

    def __init__(
        self,
        host: str = '0.0.0.0',
        port: int = 6970,
        data_dir: str = './nexadb_data',
        max_connections: int = 1000,
        max_workers: int = 100
    ):
        """
        Initialize binary protocol server.

        Args:
            host: Host to bind to
            port: Port to listen on
            data_dir: Database data directory
            max_connections: Maximum concurrent connections
            max_workers: Thread pool size
        """
        self.host = host
        self.port = port
        self.data_dir = data_dir
        self.max_connections = max_connections
        self.max_workers = max_workers

        # Initialize database
        print(f"[INIT] Initializing NexaDB at {data_dir}")
        self.db = VeloxDB(data_dir)

        # Initialize unified authentication (username/password + API keys)
        print(f"[SECURITY] Initializing unified authentication")
        self.auth = UnifiedAuthManager(data_dir)

        # Connection pool
        self.executor = ThreadPoolExecutor(max_workers=max_workers)

        # Socket
        self.socket = None
        self.running = False

        # Authenticated sessions: address -> {username, role, authenticated_at}
        self.sessions = {}
        self.sessions_lock = threading.Lock()

        # Change stream subscriptions: {address: {socket, collection, operations}}
        self.subscriptions = {}
        self.subscriptions_lock = threading.Lock()

        # Statistics
        self.stats = {
            'total_connections': 0,
            'active_connections': 0,
            'total_requests': 0,
            'total_errors': 0,
            'auth_failures': 0,
            'start_time': time.time()
        }
        self.stats_lock = threading.Lock()

        # Register global change stream listener
        self._setup_change_stream()

    def start(self):
        """Start binary protocol server."""
        # Create socket
        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

        # Bind and listen
        self.socket.bind((self.host, self.port))
        self.socket.listen(self.max_connections)

        self.running = True

        print("=" * 70)
        print("NexaDB Binary Protocol Server Started")
        print("=" * 70)
        print(f"Host: {self.host}")
        print(f"Port: {self.port}")
        print(f"Data Directory: {self.data_dir}")
        print(f"Max Connections: {self.max_connections}")
        print(f"Worker Threads: {self.max_workers}")
        print(f"\nServer listening on {self.host}:{self.port}")
        print("\nProtocol: Binary (MessagePack)")
        print("Performance: 3-10x faster than HTTP/REST")
        print("\nüîí SECURITY: Username/Password Authentication")
        print("   - Clients must send CONNECT with username + password")
        print("   - All operations require authentication")
        print("   - Default user: root / nexadb123")
        print("\nSupported Operations:")
        print("  - CREATE, READ, UPDATE, DELETE")
        print("  - QUERY (with filters)")
        print("  - BATCH_WRITE (bulk inserts)")
        print("  - VECTOR_SEARCH (AI/ML)")
        print("  - TOON FORMAT (40-50% token reduction for LLMs) ‚≠ê NEW!")
        print("\nüöÄ FIRST DATABASE WITH NATIVE TOON SUPPORT!")
        print("=" * 70)

        try:
            while self.running:
                # Accept connection
                client_socket, address = self.socket.accept()

                # Update stats
                with self.stats_lock:
                    self.stats['total_connections'] += 1
                    self.stats['active_connections'] += 1

                # Handle connection in thread pool
                self.executor.submit(self.handle_connection, client_socket, address)

        except KeyboardInterrupt:
            print("\n[SHUTDOWN] Shutting down server...")
            self.stop()

    def stop(self):
        """Stop server."""
        self.running = False

        if self.socket:
            self.socket.close()

        # Shutdown thread pool
        self.executor.shutdown(wait=True)

        # Close database
        self.db.close()

        print("[SHUTDOWN] Server stopped")

    def handle_connection(self, client_socket: socket.socket, address: tuple):
        """
        Handle persistent client connection.

        Args:
            client_socket: Client socket
            address: Client address (host, port)
        """
        print(f"[CONNECT] New connection from {address[0]}:{address[1]}")

        try:
            while self.running:
                # Read message header (12 bytes)
                header_bytes = self._recv_exact(client_socket, 12)
                if not header_bytes:
                    break  # Connection closed

                # Parse header
                magic, version, msg_type, flags, payload_len = NexaDBBinaryProtocol.unpack_header(header_bytes)

                # Verify magic
                if magic != NexaDBBinaryProtocol.MAGIC:
                    print(f"[ERROR] Invalid magic: {hex(magic)}")
                    self._send_error(client_socket, f"Invalid protocol magic: {hex(magic)}")
                    break

                # Verify version
                if version != NexaDBBinaryProtocol.VERSION:
                    print(f"[ERROR] Unsupported version: {version}")
                    self._send_error(client_socket, f"Unsupported protocol version: {version}")
                    break

                # Read payload
                payload_bytes = self._recv_exact(client_socket, payload_len)
                if not payload_bytes:
                    break  # Connection closed

                # Decode MessagePack
                try:
                    data = msgpack.unpackb(payload_bytes, raw=False)
                except Exception as e:
                    print(f"[ERROR] Failed to decode MessagePack: {e}")
                    self._send_error(client_socket, f"Invalid MessagePack: {e}")
                    continue

                # Update stats
                with self.stats_lock:
                    self.stats['total_requests'] += 1

                # Process message
                self._process_message(client_socket, msg_type, data, address)

        except Exception as e:
            print(f"[ERROR] Connection error from {address}: {e}")
            with self.stats_lock:
                self.stats['total_errors'] += 1

        finally:
            client_socket.close()

            # Remove session
            with self.sessions_lock:
                if address in self.sessions:
                    del self.sessions[address]

            # Remove subscription
            with self.subscriptions_lock:
                if address in self.subscriptions:
                    del self.subscriptions[address]

            with self.stats_lock:
                self.stats['active_connections'] -= 1

            print(f"[DISCONNECT] Connection closed from {address[0]}:{address[1]}")

    def _recv_exact(self, sock: socket.socket, n: int) -> Optional[bytes]:
        """
        Receive exactly n bytes from socket.

        Args:
            sock: Socket to read from
            n: Number of bytes to read

        Returns:
            Bytes read, or None if connection closed
        """
        data = b''
        while len(data) < n:
            chunk = sock.recv(n - len(data))
            if not chunk:
                return None  # Connection closed
            data += chunk
        return data

    def _send_message(self, sock: socket.socket, msg_type: int, data: Any):
        """
        Send binary message to client.

        Args:
            sock: Socket to send to
            msg_type: Message type code
            data: Data to send
        """
        message = NexaDBBinaryProtocol.pack_message(msg_type, data)
        sock.sendall(message)

    def _send_success(self, sock: socket.socket, data: Any):
        """Send success response."""
        self._send_message(sock, NexaDBBinaryProtocol.MSG_SUCCESS, data)

    def _send_error(self, sock: socket.socket, error: str):
        """Send error response."""
        self._send_message(sock, NexaDBBinaryProtocol.MSG_ERROR, {'error': error})

    def _send_not_found(self, sock: socket.socket):
        """Send not found response."""
        self._send_message(sock, NexaDBBinaryProtocol.MSG_NOT_FOUND, {'error': 'Not found'})

    def _check_database_permission(self, address: tuple, database: str, required_permission: str) -> bool:
        """
        Check if user has required permission for a database (v3.0.0).

        Permission hierarchy: admin > write > read > guest

        Args:
            address: Client address (to get session)
            database: Database name
            required_permission: Required permission level (admin, write, read, guest)

        Returns:
            True if user has permission, False otherwise
        """
        with self.sessions_lock:
            session = self.sessions.get(address)
            if not session:
                return False

            # Admin role has access to all databases
            if session['role'] == 'admin':
                return True

            # Check database-specific permissions
            db_permissions = session.get('database_permissions', {})

            # If no specific permission for this database, deny access
            if database not in db_permissions:
                return False

            # Permission hierarchy
            permission_levels = {'guest': 1, 'read': 2, 'write': 3, 'admin': 4}

            user_level = permission_levels.get(db_permissions[database], 0)
            required_level = permission_levels.get(required_permission, 0)

            return user_level >= required_level

    def _process_message(self, sock: socket.socket, msg_type: int, data: Dict[str, Any], address: tuple):
        """
        Process incoming message and send response.

        Args:
            sock: Client socket
            msg_type: Message type code
            data: Message data
            address: Client address
        """
        try:
            if msg_type == NexaDBBinaryProtocol.MSG_CONNECT:
                # CONNECT - Handshake + Authentication
                self._handle_connect(sock, data, address)
                return  # Don't check auth for CONNECT itself

            # Check authentication for all other operations
            with self.sessions_lock:
                if address not in self.sessions:
                    self._send_error(sock, "Not authenticated. Send CONNECT message with API key first.")
                    return

            if msg_type == NexaDBBinaryProtocol.MSG_CREATE:
                # CREATE - Insert document
                self._handle_create(sock, data, address)

            elif msg_type == NexaDBBinaryProtocol.MSG_READ:
                # READ - Get document by key
                self._handle_read(sock, data, address)

            elif msg_type == NexaDBBinaryProtocol.MSG_UPDATE:
                # UPDATE - Update document
                self._handle_update(sock, data, address)

            elif msg_type == NexaDBBinaryProtocol.MSG_DELETE:
                # DELETE - Delete document
                self._handle_delete(sock, data, address)

            elif msg_type == NexaDBBinaryProtocol.MSG_QUERY:
                # QUERY - Query with filters
                self._handle_query(sock, data, address)

            elif msg_type == NexaDBBinaryProtocol.MSG_VECTOR_SEARCH:
                # VECTOR_SEARCH - Vector similarity search
                self._handle_vector_search(sock, data, address)

            elif msg_type == NexaDBBinaryProtocol.MSG_BATCH_WRITE:
                # BATCH_WRITE - Bulk insert
                self._handle_batch_write(sock, data, address)

            elif msg_type == NexaDBBinaryProtocol.MSG_PING:
                # PING - Keep-alive
                self._handle_ping(sock, data)

            elif msg_type == NexaDBBinaryProtocol.MSG_DISCONNECT:
                # DISCONNECT - Graceful close
                self._send_success(sock, {'status': 'goodbye'})
                sock.close()

            elif msg_type == NexaDBBinaryProtocol.MSG_QUERY_TOON:
                # QUERY_TOON - Query with TOON format response
                self._handle_query_toon(sock, data)

            elif msg_type == NexaDBBinaryProtocol.MSG_EXPORT_TOON:
                # EXPORT_TOON - Export collection to TOON format
                self._handle_export_toon(sock, data)

            elif msg_type == NexaDBBinaryProtocol.MSG_IMPORT_TOON:
                # IMPORT_TOON - Import TOON data into collection
                self._handle_import_toon(sock, data)

            elif msg_type == NexaDBBinaryProtocol.MSG_CREATE_USER:
                # CREATE_USER - Create new user (admin only)
                self._handle_create_user(sock, data, address)

            elif msg_type == NexaDBBinaryProtocol.MSG_DELETE_USER:
                # DELETE_USER - Delete user (admin only)
                self._handle_delete_user(sock, data, address)

            elif msg_type == NexaDBBinaryProtocol.MSG_LIST_USERS:
                # LIST_USERS - List all users (admin only)
                self._handle_list_users(sock, address)

            elif msg_type == NexaDBBinaryProtocol.MSG_CHANGE_PASSWORD:
                # CHANGE_PASSWORD - Change user password
                self._handle_change_password(sock, data, address)

            elif msg_type == NexaDBBinaryProtocol.MSG_LIST_COLLECTIONS:
                # LIST_COLLECTIONS - List all collections
                self._handle_list_collections(sock, data, address)

            elif msg_type == NexaDBBinaryProtocol.MSG_DROP_COLLECTION:
                # DROP_COLLECTION - Drop a collection
                self._handle_drop_collection(sock, data, address)

            elif msg_type == NexaDBBinaryProtocol.MSG_GET_VECTORS:
                # GET_VECTORS - Get vector statistics
                self._handle_get_vectors(sock, data)

            elif msg_type == NexaDBBinaryProtocol.MSG_SUBSCRIBE_CHANGES:
                # SUBSCRIBE_CHANGES - Subscribe to change stream
                self._handle_subscribe_changes(sock, data, address)

            elif msg_type == NexaDBBinaryProtocol.MSG_UNSUBSCRIBE_CHANGES:
                # UNSUBSCRIBE_CHANGES - Unsubscribe from change stream
                self._handle_unsubscribe_changes(sock, data, address)

            elif msg_type == NexaDBBinaryProtocol.MSG_LIST_DATABASES:
                # LIST_DATABASES - List all databases (NEW v3.0.0)
                self._handle_list_databases(sock)

            elif msg_type == NexaDBBinaryProtocol.MSG_DROP_DATABASE:
                # DROP_DATABASE - Drop a database (NEW v3.0.0)
                self._handle_drop_database(sock, data)

            elif msg_type == NexaDBBinaryProtocol.MSG_IMPORT_MONGODB_DB:
                # IMPORT_MONGODB_DB - Import entire MongoDB database (NEW v3.0.0)
                self._handle_import_mongodb_database(sock, data)

            elif msg_type == NexaDBBinaryProtocol.MSG_IMPORT_MONGODB_COLLECTION:
                # IMPORT_MONGODB_COLLECTION - Import single collection (NEW v3.0.0)
                self._handle_import_mongodb_collection(sock, data)

            elif msg_type == NexaDBBinaryProtocol.MSG_BUILD_HNSW_INDEX:
                # BUILD_HNSW_INDEX - Build/rebuild HNSW index for vector collection (NEW v3.0.0)
                self._handle_build_hnsw_index(sock, data, address)

            else:
                self._send_error(sock, f"Unknown message type: {msg_type}")

        except Exception as e:
            print(f"[ERROR] Failed to process message: {e}")
            self._send_error(sock, str(e))

            with self.stats_lock:
                self.stats['total_errors'] += 1

    def _handle_connect(self, sock: socket.socket, data: Dict[str, Any], address: tuple):
        """
        Handle CONNECT message with username/password authentication.

        Args:
            sock: Client socket
            data: Connection data with 'username' and 'password' fields
            address: Client address
        """
        username = data.get('username')
        password = data.get('password')

        if not username or not password:
            self._send_error(sock, "Missing 'username' or 'password' field in CONNECT message")
            with self.stats_lock:
                self.stats['auth_failures'] += 1
            return

        # Authenticate user
        user_info = self.auth.authenticate_password(username, password)

        if not user_info:
            self._send_error(sock, "Invalid username or password")
            with self.stats_lock:
                self.stats['auth_failures'] += 1
            return

        # Get user's full info including database permissions (v3.0.0)
        user_full = self.auth.get_user(user_info['username'])
        database_permissions = user_full.get('database_permissions', {}) if user_full else {}

        # Store session
        with self.sessions_lock:
            self.sessions[address] = {
                'username': user_info['username'],
                'role': user_info['role'],
                'database_permissions': database_permissions,  # NEW v3.0.0
                'authenticated_at': time.time()
            }

        print(f"[AUTH] User '{user_info['username']}' (role: {user_info['role']}) authenticated from {address[0]}:{address[1]}")

        self._send_success(sock, {
            'status': 'connected',
            'server': 'NexaDB Binary Protocol',
            'version': '1.0.0',
            'authenticated': True,
            'username': user_info['username'],
            'role': user_info['role']
        })

    def _handle_create(self, sock: socket.socket, data: Dict[str, Any], address: tuple = None):
        """Handle CREATE message."""
        # NEW v3.0.0: Check if this is database creation
        if data.get('create_database'):
            database_name = data.get('database')

            if not database_name:
                self._send_error(sock, "Missing 'database' field")
                return

            # Check if current user is admin
            with self.sessions_lock:
                session = self.sessions.get(address)
                if not session or session['role'] != 'admin':
                    self._send_error(sock, "Permission denied. Only admins can create databases.")
                    return

            # Database is created implicitly when first accessed
            # Just verify it by accessing it
            db = self.db.database(database_name)

            print(f"[DATABASE] Admin '{session['username']}' created database '{database_name}'")

            self._send_success(sock, {
                'database': database_name,
                'message': 'Database created'
            })
            return

        # Regular document creation
        database_name = data.get('database', 'default')  # NEW v3.0.0: Database support
        collection_name = data.get('collection')
        document = data.get('data')

        if not collection_name or not document:
            self._send_error(sock, "Missing 'collection' or 'data' field")
            return

        # NEW v3.0.0: Check database permission
        if address and not self._check_database_permission(address, database_name, 'write'):
            self._send_error(sock, f"Permission denied: You don't have 'write' access to database '{database_name}'")
            return

        # Get database
        db = self.db.database(database_name)

        # Check if document has vector field for automatic indexing
        if 'vector' in document and isinstance(document['vector'], list):
            # Auto-index vector for similarity search
            vector = document['vector']
            dimensions = len(vector)

            # Validate vector dimensions against collection metadata
            # First check if collection has a marker with dimensions spec
            collection = db.collection(collection_name)
            all_docs = collection.find({'_nexadb_collection_marker': True}, limit=1)

            expected_dimensions = None
            if all_docs:
                marker = all_docs[0]
                if '_vector_dimensions' in marker:
                    expected_dimensions = marker['_vector_dimensions']

            # If no marker dimensions, check against existing vectors
            if expected_dimensions is None:
                vector_prefix = f"db:{database_name}:vector:{collection_name}:"
                existing_vectors_iter = self.db.engine.range_scan(vector_prefix, vector_prefix + '\xff')

                # Get first vector if it exists
                first_vector = None
                try:
                    for vec in existing_vectors_iter:
                        first_vector = vec
                        break  # Only get the first one
                except:
                    pass

                if first_vector:
                    # Collection has vectors, use their dimensions
                    try:
                        import json
                        existing_vector = json.loads(first_vector[1].decode('utf-8'))
                        expected_dimensions = len(existing_vector)
                    except:
                        pass  # If we can't decode, proceed

            # Validate dimensions if we have expected dimensions
            if expected_dimensions is not None and dimensions != expected_dimensions:
                self._send_error(sock, f"Vector dimension mismatch: collection expects {expected_dimensions} dimensions, got {dimensions}")
                return

            # Insert via vector collection (indexes vector automatically)
            vector_collection = db.vector_collection(collection_name, dimensions)
            doc_data = {k: v for k, v in document.items() if k != 'vector'}
            doc_id = vector_collection.insert(doc_data, vector)
        else:
            # Regular insert (no vector)
            collection = db.collection(collection_name)
            doc_id = collection.insert(document)

        self._send_success(sock, {
            'database': database_name,
            'collection': collection_name,
            'document_id': doc_id,
            'message': 'Document inserted'
        })

    def _handle_read(self, sock: socket.socket, data: Dict[str, Any], address: tuple = None):
        """Handle READ message."""
        database_name = data.get('database', 'default')  # NEW v3.0.0: Database support
        collection_name = data.get('collection')
        doc_id = data.get('key')

        if not collection_name or not doc_id:
            self._send_error(sock, "Missing 'collection' or 'key' field")
            return

        # NEW v3.0.0: Check database permission
        if address and not self._check_database_permission(address, database_name, 'read'):
            self._send_error(sock, f"Permission denied: You don't have 'read' access to database '{database_name}'")
            return

        # Get database and collection
        db = self.db.database(database_name)
        collection = db.collection(collection_name)
        document = collection.find_by_id(doc_id)

        if document:
            self._send_success(sock, {
                'database': database_name,
                'collection': collection_name,
                'document': document
            })
        else:
            self._send_not_found(sock)

    def _handle_update(self, sock: socket.socket, data: Dict[str, Any], address: tuple = None):
        """Handle UPDATE message."""
        database_name = data.get('database', 'default')  # NEW v3.0.0: Database support
        collection_name = data.get('collection')
        doc_id = data.get('key')
        updates = data.get('updates')

        if not collection_name or not doc_id or not updates:
            self._send_error(sock, "Missing 'collection', 'key', or 'updates' field")
            return

        # NEW v3.0.0: Check database permission
        if address and not self._check_database_permission(address, database_name, 'write'):
            self._send_error(sock, f"Permission denied: You don't have 'write' access to database '{database_name}'")
            return

        # Get database and collection
        db = self.db.database(database_name)
        collection = db.collection(collection_name)
        success = collection.update(doc_id, updates)

        if success:
            self._send_success(sock, {
                'database': database_name,
                'collection': collection_name,
                'document_id': doc_id,
                'message': 'Document updated'
            })
        else:
            self._send_not_found(sock)

    def _handle_delete(self, sock: socket.socket, data: Dict[str, Any], address: tuple = None):
        """Handle DELETE message."""
        database_name = data.get('database', 'default')  # NEW v3.0.0: Database support
        collection_name = data.get('collection')
        doc_id = data.get('key')

        if not collection_name or not doc_id:
            self._send_error(sock, "Missing 'collection' or 'key' field")
            return

        # NEW v3.0.0: Check database permission
        if address and not self._check_database_permission(address, database_name, 'write'):
            self._send_error(sock, f"Permission denied: You don't have 'write' access to database '{database_name}'")
            return

        # Get database and collection
        db = self.db.database(database_name)
        collection = db.collection(collection_name)
        success = collection.delete(doc_id)

        if success:
            self._send_success(sock, {
                'database': database_name,
                'collection': collection_name,
                'document_id': doc_id,
                'message': 'Document deleted'
            })
        else:
            self._send_not_found(sock)

    def _handle_query(self, sock: socket.socket, data: Dict[str, Any], address: tuple = None):
        """Handle QUERY message."""
        database_name = data.get('database', 'default')  # NEW v3.0.0: Database support
        collection_name = data.get('collection')
        filters = data.get('filters', {})
        limit = data.get('limit', 100)

        if not collection_name:
            self._send_error(sock, "Missing 'collection' field")
            return

        # NEW v3.0.0: Check database permission
        if address and not self._check_database_permission(address, database_name, 'read'):
            self._send_error(sock, f"Permission denied: You don't have 'read' access to database '{database_name}'")
            return

        # Get database and collection
        db = self.db.database(database_name)
        collection = db.collection(collection_name)
        documents = collection.find(filters, limit=limit)

        self._send_success(sock, {
            'database': database_name,
            'collection': collection_name,
            'documents': documents,
            'count': len(documents)
        })

    def _handle_vector_search(self, sock: socket.socket, data: Dict[str, Any], address: tuple = None):
        """Handle VECTOR_SEARCH message."""
        database_name = data.get('database', 'default')  # NEW v3.0.0: Database support
        collection_name = data.get('collection')
        vector = data.get('vector')
        limit = data.get('limit', 10)
        dimensions = data.get('dimensions', 768)
        filters = data.get('filters')  # Optional metadata filters

        if not collection_name or not vector:
            self._send_error(sock, "Missing 'collection' or 'vector' field")
            return

        # NEW v3.0.0: Check database permission
        if address and not self._check_database_permission(address, database_name, 'read'):
            self._send_error(sock, f"Permission denied: You don't have 'read' access to database '{database_name}'")
            return

        # Get database and vector collection
        db = self.db.database(database_name)
        vector_collection = db.vector_collection(collection_name, dimensions)
        results = vector_collection.search(vector, limit=limit)

        # Format results
        formatted_results = []
        for doc_id, similarity, doc in results:
            # Apply metadata filters if provided
            if filters:
                # Check if document matches all filters
                matches = True
                for field, condition in filters.items():
                    doc_value = doc.get(field)
                    if isinstance(condition, dict):
                        # Handle operators like {'$gte': 100}
                        for operator, operand in condition.items():
                            if operator == '$gte' and not (doc_value >= operand):
                                matches = False
                                break
                            elif operator == '$lte' and not (doc_value <= operand):
                                matches = False
                                break
                            elif operator == '$gt' and not (doc_value > operand):
                                matches = False
                                break
                            elif operator == '$lt' and not (doc_value < operand):
                                matches = False
                                break
                    else:
                        # Simple equality check
                        if doc_value != condition:
                            matches = False
                            break
                if not matches:
                    continue

            formatted_results.append({
                'document_id': doc_id,
                'similarity': float(similarity),
                'document': doc
            })

        self._send_success(sock, {
            'database': database_name,
            'collection': collection_name,
            'results': formatted_results,
            'count': len(formatted_results)
        })

    def _handle_batch_write(self, sock: socket.socket, data: Dict[str, Any], address: tuple = None):
        """Handle BATCH_WRITE message."""
        database_name = data.get('database', 'default')  # NEW v3.0.0: Database support
        collection_name = data.get('collection')
        documents = data.get('documents', [])

        if not collection_name or not documents:
            self._send_error(sock, "Missing 'collection' or 'documents' field")
            return

        # NEW v3.0.0: Check database permission
        if address and not self._check_database_permission(address, database_name, 'write'):
            self._send_error(sock, f"Permission denied: You don't have 'write' access to database '{database_name}'")
            return

        # Get database
        db = self.db.database(database_name)

        # Check if documents have vector fields for automatic indexing
        has_vectors = any('vector' in doc and isinstance(doc.get('vector'), list) for doc in documents)

        if has_vectors:
            # Use vector collection for automatic indexing with BATCH operations (100x faster!)
            # Get dimensions from first document with vector
            dimensions = None
            for doc in documents:
                if 'vector' in doc and isinstance(doc['vector'], list):
                    dimensions = len(doc['vector'])
                    break

            vector_collection = db.vector_collection(collection_name, dimensions)

            # Separate vector documents from regular documents
            vector_docs = []
            regular_docs = []

            for doc in documents:
                if 'vector' in doc and isinstance(doc['vector'], list):
                    vector = doc['vector']
                    doc_data = {k: v for k, v in doc.items() if k != 'vector'}
                    vector_docs.append((doc_data, vector))
                else:
                    regular_docs.append(doc)

            # Batch insert vector documents (FAST!)
            doc_ids = []
            if vector_docs:
                result = vector_collection.insert_batch(vector_docs)
                doc_ids.extend(result['successful'])

                # Log failures if any
                if result['failed']:
                    print(f"[BATCH_WRITE] {len(result['failed'])} documents failed to insert")

            # Insert regular documents
            if regular_docs:
                collection = db.collection(collection_name)
                for doc in regular_docs:
                    doc_id = collection.insert(doc)
                    doc_ids.append(doc_id)
        else:
            # Regular bulk insert (no vectors)
            collection = db.collection(collection_name)
            doc_ids = collection.insert_many(documents)

        self._send_success(sock, {
            'database': database_name,
            'collection': collection_name,
            'document_ids': doc_ids,
            'count': len(doc_ids),
            'message': f'Inserted {len(doc_ids)} documents'
        })

    def _handle_ping(self, sock: socket.socket, data: Dict[str, Any]):
        """Handle PING message."""
        self._send_message(sock, NexaDBBinaryProtocol.MSG_PONG, {
            'status': 'ok',
            'timestamp': time.time()
        })

    def _handle_query_toon(self, sock: socket.socket, data: Dict[str, Any]):
        """
        Handle QUERY_TOON message.

        Query collection and return results in TOON format.
        TOON format reduces token count by ~40-50% for LLM applications.
        """
        database_name = data.get('database', 'default')  # NEW v3.0.0: Database support
        collection_name = data.get('collection')
        filters = data.get('filters', {})
        limit = data.get('limit', 100)

        if not collection_name:
            self._send_error(sock, "Missing 'collection' field")
            return

        # Get database and collection
        db = self.db.database(database_name)
        collection = db.collection(collection_name)
        documents = collection.find(filters, limit=limit)

        # Convert to TOON format
        toon_data = json_to_toon({
            'collection': collection_name,
            'documents': documents,
            'count': len(documents)
        })

        # Calculate token savings
        import json
        json_size = len(json.dumps({'documents': documents}))
        toon_size = len(toon_data)
        token_reduction = ((json_size - toon_size) / json_size * 100) if json_size > 0 else 0

        self._send_success(sock, {
            'database': database_name,
            'collection': collection_name,
            'format': 'TOON',
            'data': toon_data,
            'count': len(documents),
            'token_stats': {
                'json_size': json_size,
                'toon_size': toon_size,
                'reduction_percent': round(token_reduction, 1)
            }
        })

    def _handle_export_toon(self, sock: socket.socket, data: Dict[str, Any]):
        """
        Handle EXPORT_TOON message.

        Export entire collection to TOON format.
        Perfect for AI/ML pipelines that need efficient data transfer.
        """
        database_name = data.get('database', 'default')  # NEW v3.0.0: Database support
        collection_name = data.get('collection')

        if not collection_name:
            self._send_error(sock, "Missing 'collection' field")
            return

        # Get database and collection
        db = self.db.database(database_name)
        collection = db.collection(collection_name)
        all_documents = collection.find({}, limit=10000)  # Export up to 10K docs

        # Convert to TOON format
        toon_data = json_to_toon({
            'collection': collection_name,
            'documents': all_documents,
            'count': len(all_documents),
            'exported_at': time.time()
        })

        # Calculate statistics
        import json
        json_size = len(json.dumps(all_documents))
        toon_size = len(toon_data)
        token_reduction = ((json_size - toon_size) / json_size * 100) if json_size > 0 else 0

        self._send_success(sock, {
            'database': database_name,
            'collection': collection_name,
            'format': 'TOON',
            'data': toon_data,
            'count': len(all_documents),
            'token_stats': {
                'json_size': json_size,
                'toon_size': toon_size,
                'reduction_percent': round(token_reduction, 1),
                'estimated_cost_savings': f"~{round(token_reduction, 0)}% less tokens for LLM processing"
            }
        })

    def _handle_import_toon(self, sock: socket.socket, data: Dict[str, Any]):
        """
        Handle IMPORT_TOON message.

        Import TOON formatted data into a collection.
        Automatically converts TOON to JSON for storage.
        """
        database_name = data.get('database', 'default')  # NEW v3.0.0: Database support
        collection_name = data.get('collection')
        toon_data = data.get('toon_data')
        replace = data.get('replace', False)  # Replace existing collection?

        if not collection_name:
            self._send_error(sock, "Missing 'collection' field")
            return

        if not toon_data:
            self._send_error(sock, "Missing 'toon_data' field")
            return

        try:
            # Convert TOON to JSON
            import json
            json_str = toon_to_json(toon_data)
            parsed_data = json.loads(json_str)

            # Extract documents
            documents = []
            if isinstance(parsed_data, dict):
                # Check if it has a 'documents' field (export format)
                if 'documents' in parsed_data:
                    documents = parsed_data['documents']
                else:
                    # Single document
                    documents = [parsed_data]
            elif isinstance(parsed_data, list):
                # Array of documents
                documents = parsed_data
            else:
                self._send_error(sock, "Invalid TOON data structure")
                return

            # Get database and collection
            db = self.db.database(database_name)
            collection = db.collection(collection_name)

            # Replace existing data if requested
            if replace:
                # Delete all existing documents
                all_docs = collection.find({}, limit=100000)
                for doc in all_docs:
                    collection.delete(doc.get('_id'))

            # Insert documents
            doc_ids = collection.insert_many(documents)

            self._send_success(sock, {
                'database': database_name,
                'collection': collection_name,
                'imported': len(doc_ids),
                'replaced': replace,
                'document_ids': doc_ids[:100],  # Return first 100 IDs
                'message': f"Successfully imported {len(doc_ids)} documents from TOON format"
            })

        except Exception as e:
            self._send_error(sock, f"Failed to import TOON data: {str(e)}")

    def _handle_create_user(self, sock: socket.socket, data: Dict[str, Any], address: tuple):
        """Handle CREATE_USER message (admin only)."""
        # Check if current user is admin
        with self.sessions_lock:
            session = self.sessions.get(address)
            if not session or session['role'] != 'admin':
                self._send_error(sock, "Permission denied. Only admins can create users.")
                return

        username = data.get('username')
        password = data.get('password')
        role = data.get('role', 'read')

        if not username or not password:
            self._send_error(sock, "Missing 'username' or 'password' field")
            return

        # Validate role
        valid_roles = ['admin', 'write', 'read', 'guest']
        if role not in valid_roles:
            self._send_error(sock, f"Invalid role. Must be one of: {', '.join(valid_roles)}")
            return

        # Create user (returns API key)
        try:
            api_key = self.auth.create_user(username, password, role)

            print(f"[USER] Admin '{session['username']}' created user '{username}' with role '{role}'")

            self._send_success(sock, {
                'message': f"User '{username}' created successfully",
                'username': username,
                'password': password,  # Return so admin can give it to the user
                'api_key': api_key,    # Return so admin can give it to the user
                'role': role,
                'note': '‚ö†Ô∏è Save these credentials! Password and API key are only shown once.'
            })
        except ValueError as e:
            self._send_error(sock, str(e))

    def _handle_delete_user(self, sock: socket.socket, data: Dict[str, Any], address: tuple):
        """Handle DELETE_USER message (admin only)."""
        # Check if current user is admin
        with self.sessions_lock:
            session = self.sessions.get(address)
            if not session or session['role'] != 'admin':
                self._send_error(sock, "Permission denied. Only admins can delete users.")
                return

        username = data.get('username')

        if not username:
            self._send_error(sock, "Missing 'username' field")
            return

        # Delete user
        success = self.auth.delete_user(username)

        if success:
            print(f"[USER] Admin '{session['username']}' deleted user '{username}'")
            self._send_success(sock, {
                'message': f"User '{username}' deleted successfully"
            })
        else:
            self._send_error(sock, f"Failed to delete user '{username}' (may be root or doesn't exist)")

    def _handle_list_users(self, sock: socket.socket, address: tuple):
        """Handle LIST_USERS message (admin only)."""
        # Check if current user is admin
        with self.sessions_lock:
            session = self.sessions.get(address)
            if not session or session['role'] != 'admin':
                self._send_error(sock, "Permission denied. Only admins can list users.")
                return

        # List users
        users = self.auth.list_users()

        self._send_success(sock, {
            'users': users,
            'count': len(users)
        })

    def _handle_change_password(self, sock: socket.socket, data: Dict[str, Any], address: tuple):
        """Handle CHANGE_PASSWORD message."""
        with self.sessions_lock:
            session = self.sessions.get(address)

        username = data.get('username')
        new_password = data.get('new_password')

        if not username or not new_password:
            self._send_error(sock, "Missing 'username' or 'new_password' field")
            return

        # Users can change their own password, admins can change any password
        if session['username'] != username and session['role'] != 'admin':
            self._send_error(sock, "Permission denied. You can only change your own password.")
            return

        # Change password
        success = self.auth.change_password(username, new_password)

        if success:
            print(f"[USER] Password changed for user '{username}' by '{session['username']}'")
            self._send_success(sock, {
                'message': f"Password changed successfully for user '{username}'"
            })
        else:
            self._send_error(sock, f"Failed to change password for user '{username}'")

    def _handle_list_collections(self, sock: socket.socket, data: Dict[str, Any] = None, address: tuple = None):
        """Handle LIST_COLLECTIONS message."""
        try:
            # NEW v3.0.0: Check if requesting database list
            if data and data.get('database') == True:
                databases = self.db.list_databases()

                self._send_success(sock, {
                    'databases': databases,
                    'count': len(databases)
                })
                return

            # Regular collection listing
            database_name = data.get('database', 'default') if data and isinstance(data.get('database'), str) else 'default'

            # NEW v3.0.0: Check database permission
            if address and not self._check_database_permission(address, database_name, 'read'):
                self._send_error(sock, f"Permission denied: You don't have 'read' access to database '{database_name}'")
                return

            # Get database and list collections
            db = self.db.database(database_name)
            collections = db.list_collections()

            self._send_success(sock, {
                'database': database_name,
                'collections': collections,
                'count': len(collections)
            })
        except Exception as e:
            self._send_error(sock, f"Failed to list collections: {str(e)}")

    def _handle_drop_collection(self, sock: socket.socket, data: Dict[str, Any], address: tuple = None):
        """Handle DROP_COLLECTION message."""
        # NEW v3.0.0: Check if this is database drop
        if data.get('drop_database'):
            database_name = data.get('database')

            if not database_name:
                self._send_error(sock, "Missing 'database' field")
                return

            # Check if current user is admin
            with self.sessions_lock:
                session = self.sessions.get(address)
                if not session or session['role'] != 'admin':
                    self._send_error(sock, "Permission denied. Only admins can drop databases.")
                    return

            # Prevent dropping critical databases
            if database_name == 'default':
                self._send_error(sock, "Cannot drop 'default' database")
                return

            try:
                success = self.db.drop_database(database_name)

                if success:
                    print(f"[DATABASE] Admin '{session['username']}' dropped database '{database_name}'")
                    self._send_success(sock, {
                        'success': True,
                        'database': database_name,
                        'message': f"Database '{database_name}' dropped successfully"
                    })
                else:
                    self._send_error(sock, f"Database '{database_name}' not found")
            except Exception as e:
                self._send_error(sock, f"Failed to drop database: {str(e)}")
            return

        # Regular collection drop
        database_name = data.get('database', 'default')  # NEW v3.0.0: Database support
        collection_name = data.get('collection')

        if not collection_name:
            self._send_error(sock, "Missing 'collection' field")
            return

        # NEW v3.0.0: Check database permission (requires admin)
        if address and not self._check_database_permission(address, database_name, 'admin'):
            self._send_error(sock, f"Permission denied: You need 'admin' access to drop collections in database '{database_name}'")
            return

        try:
            # Get database and drop collection
            db = self.db.database(database_name)
            success = db.drop_collection(collection_name)

            if success:
                self._send_success(sock, {
                    'database': database_name,
                    'collection': collection_name,
                    'message': 'Collection dropped'
                })
            else:
                self._send_error(sock, f"Collection '{collection_name}' not found in database '{database_name}'")
        except Exception as e:
            self._send_error(sock, f"Failed to drop collection: {str(e)}")

    def _handle_get_vectors(self, sock: socket.socket, data: Dict[str, Any] = None):
        """Handle GET_VECTORS message - get vector index statistics."""
        try:
            from collections import defaultdict

            # NEW v3.0.0: Support database parameter
            database_name = data.get('database', 'default') if data else 'default'

            # Scan for all vectors in this database
            # NEW format: db:{database}:vector:{collection}:{doc_id}
            vector_prefix = f'db:{database_name}:vector:'
            all_vectors = list(self.db.engine.range_scan(vector_prefix, vector_prefix + '\xff'))

            # Group by collection and get detailed info
            vector_data = defaultdict(lambda: {'count': 0, 'documents': []})

            for key, vector_bytes in all_vectors:
                # key format: db:{database}:vector:{collection}:{doc_id}
                parts = key.split(':')
                if len(parts) >= 5:
                    collection = parts[3]
                    doc_id = parts[4]

                    # Parse vector to get dimensions
                    vector = json.loads(vector_bytes.decode('utf-8'))
                    dimensions = len(vector)

                    vector_data[collection]['count'] += 1
                    vector_data[collection]['documents'].append({
                        'doc_id': doc_id,
                        'dimensions': dimensions
                    })

                    # Store dimensions for this collection (should be consistent)
                    if 'dimensions' not in vector_data[collection]:
                        vector_data[collection]['dimensions'] = dimensions

            # Format response
            self._send_success(sock, {
                'database': database_name,
                'status': 'success',
                'total_vectors': len(all_vectors),
                'collections': dict(vector_data)
            })
        except Exception as e:
            self._send_error(sock, f"Failed to get vectors: {str(e)}")

    def _setup_change_stream(self):
        """Setup global change stream listener to broadcast events to subscribed clients."""
        def broadcast_change(event):
            """Broadcast change event to all subscribed clients (async)."""
            def _send_async():
                event_collection = event['ns']['coll']
                event_operation = event['operationType']

                with self.subscriptions_lock:
                    # Find all subscribed clients that match this event
                    for address, sub_info in list(self.subscriptions.items()):
                        try:
                            # Check if client is subscribed to this collection
                            if sub_info['collection'] and sub_info['collection'] != event_collection:
                                continue  # Skip if subscribed to different collection

                            # Check if client is subscribed to this operation
                            if event_operation not in sub_info['operations']:
                                continue  # Skip if not subscribed to this operation

                            # Send change event to client
                            try:
                                self._send_message(
                                    sub_info['socket'],
                                    NexaDBBinaryProtocol.MSG_CHANGE_EVENT,
                                    event
                                )
                            except Exception as e:
                                print(f"[CHANGE_STREAM] Failed to send event to {address}: {e}")
                                # Remove failed subscription
                                del self.subscriptions[address]

                        except Exception as e:
                            print(f"[CHANGE_STREAM] Error processing subscription for {address}: {e}")

            # Send events asynchronously to avoid blocking the main thread
            threading.Thread(target=_send_async, daemon=True).start()

        # Register global listener for all operations
        for operation in ['insert', 'update', 'delete', 'dropCollection']:
            self.db.change_stream.on(operation, broadcast_change)

        print("[CHANGE_STREAM] Global change stream listener registered")

    def _handle_subscribe_changes(self, sock: socket.socket, data: Dict[str, Any], address: tuple):
        """Handle SUBSCRIBE_CHANGES message."""
        collection = data.get('collection')  # None = watch all collections
        operations = data.get('operations', ['insert', 'update', 'delete'])

        # Store subscription
        with self.subscriptions_lock:
            self.subscriptions[address] = {
                'socket': sock,
                'collection': collection,
                'operations': operations
            }

        collection_str = collection if collection else "all collections"
        print(f"[CHANGE_STREAM] Client {address[0]}:{address[1]} subscribed to {collection_str} ({', '.join(operations)})")

        self._send_success(sock, {
            'subscribed': True,
            'collection': collection,
            'operations': operations,
            'message': f"Subscribed to change stream for {collection_str}"
        })

    def _handle_unsubscribe_changes(self, sock: socket.socket, data: Dict[str, Any], address: tuple):
        """Handle UNSUBSCRIBE_CHANGES message."""
        with self.subscriptions_lock:
            if address in self.subscriptions:
                del self.subscriptions[address]
                print(f"[CHANGE_STREAM] Client {address[0]}:{address[1]} unsubscribed from change stream")

        self._send_success(sock, {
            'unsubscribed': True,
            'message': 'Unsubscribed from change stream'
        })

    def _handle_list_databases(self, sock: socket.socket):
        """
        Handle LIST_DATABASES message.

        NEW v3.0.0: List all databases in the system
        """
        try:
            databases = self.db.list_databases()

            self._send_success(sock, {
                'databases': databases,
                'count': len(databases)
            })
        except Exception as e:
            self._send_error(sock, f"Failed to list databases: {str(e)}")

    def _handle_drop_database(self, sock: socket.socket, data: Dict[str, Any]):
        """
        Handle DROP_DATABASE message.

        NEW v3.0.0: Drop entire database and all its collections
        """
        database_name = data.get('database')

        if not database_name:
            self._send_error(sock, "Missing 'database' field")
            return

        # Prevent dropping critical databases
        if database_name == 'default':
            self._send_error(sock, "Cannot drop 'default' database")
            return

        try:
            success = self.db.drop_database(database_name)

            if success:
                self._send_success(sock, {
                    'database': database_name,
                    'message': f"Database '{database_name}' dropped successfully"
                })
            else:
                self._send_error(sock, f"Database '{database_name}' not found")
        except Exception as e:
            self._send_error(sock, f"Failed to drop database: {str(e)}")

    def _handle_import_mongodb_database(self, sock: socket.socket, data: Dict[str, Any]):
        """
        Handle IMPORT_MONGODB_DB message.

        NEW v3.0.0: Import entire MongoDB database with all collections

        Request format:
        {
            'mongodb_uri': 'mongodb://localhost:27017',
            'mongodb_database': 'source_db',
            'nexadb_database': 'target_db',
            'drop_existing': False  # Optional
        }
        """
        mongodb_uri = data.get('mongodb_uri')
        mongodb_database = data.get('mongodb_database')
        nexadb_database = data.get('nexadb_database', mongodb_database)
        drop_existing = data.get('drop_existing', False)

        if not mongodb_uri or not mongodb_database:
            self._send_error(sock, "Missing 'mongodb_uri' or 'mongodb_database' field")
            return

        try:
            # Import pymongo
            try:
                import pymongo
            except ImportError:
                self._send_error(sock, "pymongo not installed. Install with: pip install pymongo")
                return

            # Connect to MongoDB
            mongo_client = pymongo.MongoClient(mongodb_uri, serverSelectionTimeoutMS=5000)
            mongo_db = mongo_client[mongodb_database]

            # Get all collections
            collection_names = mongo_db.list_collection_names()

            # Get NexaDB database
            nexa_db = self.db.database(nexadb_database)

            # Import each collection
            imported_collections = []
            total_documents = 0

            for coll_name in collection_names:
                mongo_collection = mongo_db[coll_name]

                # Drop existing if requested
                if drop_existing:
                    nexa_db.drop_collection(coll_name)

                # Get NexaDB collection
                nexa_collection = nexa_db.collection(coll_name)

                # Fetch all documents from MongoDB (batch by batch)
                documents = list(mongo_collection.find({}))

                # Convert MongoDB ObjectId to string
                for doc in documents:
                    if '_id' in doc:
                        doc['_id'] = str(doc['_id'])

                # Batch insert into NexaDB
                if documents:
                    nexa_collection.insert_many(documents)
                    total_documents += len(documents)

                imported_collections.append({
                    'name': coll_name,
                    'count': len(documents)
                })

            mongo_client.close()

            self._send_success(sock, {
                'success': True,
                'database': nexadb_database,
                'collections_imported': len(imported_collections),
                'total_documents': total_documents,
                'collections': imported_collections
            })

        except Exception as e:
            self._send_error(sock, f"Failed to import MongoDB database: {str(e)}")

    def _handle_import_mongodb_collection(self, sock: socket.socket, data: Dict[str, Any]):
        """
        Handle IMPORT_MONGODB_COLLECTION message.

        NEW v3.0.0: Import single MongoDB collection

        Request format:
        {
            'mongodb_uri': 'mongodb://localhost:27017',
            'mongodb_database': 'source_db',
            'mongodb_collection': 'users',
            'nexadb_database': 'target_db',
            'nexadb_collection': 'users',  # Optional, defaults to same name
            'drop_existing': False  # Optional
        }
        """
        mongodb_uri = data.get('mongodb_uri')
        mongodb_database = data.get('mongodb_database')
        mongodb_collection = data.get('mongodb_collection')
        nexadb_database = data.get('nexadb_database', 'default')
        nexadb_collection = data.get('nexadb_collection', mongodb_collection)
        drop_existing = data.get('drop_existing', False)

        if not mongodb_uri or not mongodb_database or not mongodb_collection:
            self._send_error(sock, "Missing required fields: 'mongodb_uri', 'mongodb_database', or 'mongodb_collection'")
            return

        try:
            # Import pymongo
            try:
                import pymongo
            except ImportError:
                self._send_error(sock, "pymongo not installed. Install with: pip install pymongo")
                return

            # Connect to MongoDB
            mongo_client = pymongo.MongoClient(mongodb_uri, serverSelectionTimeoutMS=5000)
            mongo_db = mongo_client[mongodb_database]
            mongo_coll = mongo_db[mongodb_collection]

            # Get NexaDB database and collection
            nexa_db = self.db.database(nexadb_database)

            # Drop existing if requested
            if drop_existing:
                nexa_db.drop_collection(nexadb_collection)

            nexa_coll = nexa_db.collection(nexadb_collection)

            # Fetch all documents from MongoDB
            documents = list(mongo_coll.find({}))

            # Convert MongoDB ObjectId to string
            for doc in documents:
                if '_id' in doc:
                    doc['_id'] = str(doc['_id'])

            # Batch insert into NexaDB
            doc_count = 0
            if documents:
                nexa_coll.insert_many(documents)
                doc_count = len(documents)

            mongo_client.close()

            self._send_success(sock, {
                'success': True,
                'database': nexadb_database,
                'collection': nexadb_collection,
                'documents_imported': doc_count
            })

        except Exception as e:
            self._send_error(sock, f"Failed to import MongoDB collection: {str(e)}")

    def _handle_build_hnsw_index(self, sock: socket.socket, data: Dict[str, Any], address: tuple = None):
        """
        Handle BUILD_HNSW_INDEX message.

        NEW v3.0.0: Build or rebuild HNSW index for vector collection

        Request format:
        {
            'collection': 'embeddings',
            'database': 'default',
            'M': 16,  # Optional
            'ef_construction': 200  # Optional
        }
        """
        database_name = data.get('database', 'default')
        collection_name = data.get('collection')
        M = data.get('M')
        ef_construction = data.get('ef_construction')

        if not collection_name:
            self._send_error(sock, "Missing 'collection' field")
            return

        # NEW v3.0.0: Check database permission
        if address and not self._check_database_permission(address, database_name, 'write'):
            self._send_error(sock, f"Permission denied: You need 'write' access to build indexes in database '{database_name}'")
            return

        try:
            # Get database
            db = self.db.database(database_name)

            # Determine vector dimensions - need to scan for a vector to get dimensions
            # Scan for vectors in this collection
            vector_prefix = f"db:{database_name}:vector:{collection_name}:"
            all_vectors = list(self.db.engine.range_scan(vector_prefix, vector_prefix + '\xff'))

            if not all_vectors:
                self._send_error(sock, f"No vectors found in collection '{collection_name}'")
                return

            # Get dimensions from first vector
            first_vector_bytes = all_vectors[0][1]
            try:
                import json
                vector = json.loads(first_vector_bytes.decode('utf-8'))
                dimensions = len(vector)
            except:
                # Try numpy format
                import numpy as np
                vector = np.frombuffer(first_vector_bytes, dtype=np.float32)
                dimensions = len(vector)

            # Get vector collection
            vector_collection = db.vector_collection(collection_name, dimensions)

            # Build HNSW index with optional parameters
            result = vector_collection.build_hnsw_index(M=M, ef_construction=ef_construction)

            self._send_success(sock, result)

        except Exception as e:
            self._send_error(sock, f"Failed to build HNSW index: {str(e)}")

    def get_stats(self) -> Dict[str, Any]:
        """Get server statistics."""
        with self.stats_lock:
            uptime = time.time() - self.stats['start_time']
            return {
                **self.stats,
                'uptime_seconds': uptime,
                'requests_per_second': self.stats['total_requests'] / uptime if uptime > 0 else 0
            }


def main():
    """Main entry point for binary protocol server"""
    import os

    # Parse command-line arguments
    host = os.getenv('NEXADB_BINARY_HOST', '0.0.0.0')
    port = int(os.getenv('NEXADB_BINARY_PORT', 6970))
    data_dir = os.getenv('NEXADB_DATA_DIR', './nexadb_data')

    # Check for --help
    if '--help' in sys.argv or '-h' in sys.argv:
        print("NexaDB Binary Protocol Server")
        print("\nUsage:")
        print("  python3 nexadb_binary_server.py [options]")
        print("\nOptions:")
        print("  --host HOST        Host to bind to (default: 0.0.0.0)")
        print("  --port PORT        Port to listen on (default: 6970)")
        print("  --data-dir DIR     Data directory (default: ./nexadb_data)")
        print("\nEnvironment Variables:")
        print("  NEXADB_BINARY_HOST   Host to bind to")
        print("  NEXADB_BINARY_PORT   Port to listen on")
        print("  NEXADB_DATA_DIR      Data directory")
        print("\nPerformance:")
        print("  - 3-10x faster than HTTP/REST")
        print("  - Binary protocol with MessagePack encoding")
        print("  - Persistent TCP connections")
        print("  - 1000+ concurrent connections")
        sys.exit(0)

    # Parse command-line arguments
    for i, arg in enumerate(sys.argv):
        if arg == '--host' and i + 1 < len(sys.argv):
            host = sys.argv[i + 1]
        elif arg == '--port' and i + 1 < len(sys.argv):
            port = int(sys.argv[i + 1])
        elif arg == '--data-dir' and i + 1 < len(sys.argv):
            data_dir = sys.argv[i + 1]

    # Start server
    server = NexaDBBinaryServer(host=host, port=port, data_dir=data_dir)
    server.start()


if __name__ == '__main__':
    main()
